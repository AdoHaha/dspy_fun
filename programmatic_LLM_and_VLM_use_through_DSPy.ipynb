{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMZWAZeNY0rPP8LqSHeP6vU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdoHaha/dspy_fun/blob/main/programmatic_LLM_and_VLM_use_through_DSPy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Programmatic LLL and VLM use through DSPy.\n",
        "Code to follow along the presentation [\"Programmatic LLM and VLM use through DSPy\"](https://raw.githubusercontent.com/AdoHaha/dspy_fun/753b46cb3528eb374b943009e1eb851d7b69c4bb/programmatic%20LLM%20%26%20VLM%20use%20through%20DSPy.pdf)\n",
        "\n",
        "Igor Zubrycki\n",
        "igorzubrycki@gmail.com"
      ],
      "metadata": {
        "id": "mKfXqwSLCPI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dspy opik"
      ],
      "metadata": {
        "id": "7MsgjHG3eD-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbisvON0dxJ_"
      },
      "outputs": [],
      "source": [
        "#the notebook is intended to run from Google Colab which has \"secrets\" tab. Use different way to load your API keys otherwise\n",
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic DSPy use -- using predict"
      ],
      "metadata": {
        "id": "NyAQfbV7CyD5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4GvSOHC7CxI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "\n",
        "small_model = dspy.LM(\"gemini/gemini-2.5-flash-lite\", api_key=GEMINI_API_KEY)\n",
        "dspy.configure(lm=small_model)\n",
        "sum_of_numbers = dspy.Predict('numbers -> sum_of_numbers') #we want the input be numbers and the output being their sum\n",
        "result = sum_of_numbers(numbers = (12,13,15))\n",
        "\n",
        "print(result)\n",
        "\n"
      ],
      "metadata": {
        "id": "c_spvED0eM-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numbers do not neccesarely need to be a list or a string, any numbers will do\n",
        "image_url = \"https://raw.githubusercontent.com/AdoHaha/dspy_fun/refs/heads/main/example_files/image_numbers.png\" #nano banana generated numbers\n",
        "numbers_image = dspy.Image.from_url(image_url)\n",
        "from IPython.display import Image\n",
        "display(Image(image_url, width=300))"
      ],
      "metadata": {
        "id": "Ltx7I9h2ePUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = sum_of_numbers(numbers = numbers_image)\n",
        "\n",
        "print(result) #we gave the model the freedom of type of answer\n",
        "\n",
        "# you can ensure that result is float by simply adding\n",
        "sum_of_numbers = dspy.Predict('numbers -> sum_of_numbers:float')\n",
        "result = sum_of_numbers(numbers = numbers_image)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "4nkwhRPWgHBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_of_numbers.history[-1] # history can show us how the signature and function call are converted by an adapter to a prompt"
      ],
      "metadata": {
        "id": "MdAIE0nGgnQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Being more precise with Signatures"
      ],
      "metadata": {
        "id": "JOw75X5LDnme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "class NumberAdd(dspy.Signature):\n",
        " \"\"\"Please add numbers provided in a various ways together. Numbers can also be symbolic or require computation.\n",
        " Single number is also ok\n",
        " Only if there are no numbers in input, write a sad haiku using the contents of input. \"\"\"\n",
        " numbers = dspy.InputField(description=\"numbers to add\")\n",
        " sum_of_numbers: float = dspy.OutputField(description=\"resulting sum\")\n",
        " haiku: Optional[str] = dspy.OutputField(description=\"sad haiku\")\n",
        "\n",
        " #note that the type can be also a previously specified signature\n"
      ],
      "metadata": {
        "id": "G83qeQ5VhUnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_of_numbers_haiku = dspy.Predict(NumberAdd)\n"
      ],
      "metadata": {
        "id": "U9E7GuEylGYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_of_numbers_haiku(numbers = \"one, two\")"
      ],
      "metadata": {
        "id": "otGv4pDVls9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_of_numbers_haiku(numbers = \"dog, bowl\")"
      ],
      "metadata": {
        "id": "OMPrR_nolw35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can also create signatures for visual tasks\n",
        "\n",
        "\n",
        "from typing import List, Dict\n",
        "\n",
        "class NumberDetections(dspy.Signature):\n",
        "    \"\"\"Detect all numbers (not single digits) in the image and return their bounding boxes.\n",
        "\n",
        "    Boxes use pixel coords in xyxy format: x_min, y_min, x_max, y_max.\n",
        "    Return an empty list if no numbers are found.\n",
        "    \"\"\"\n",
        "    image: dspy.Image = dspy.InputField(desc=\"Image to analyze.\")\n",
        "    boxes: List[Dict] = dspy.OutputField(\n",
        "        desc=\"One dict per number in normalized coordinates (0-1000): {'x_min': int, 'y_min': int,'x_max': int, 'y_max': int, 'number':float}\")\n",
        "\n",
        "\n",
        "#To have more ready made input types use attachements library: https://github.com/maximerivest/Attachments (full texts, multiple files etc)\n",
        "#!pip install attachments\n",
        "\n"
      ],
      "metadata": {
        "id": "it51C34DBFOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing modules\n",
        "\n",
        "import urllib.request\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IyOwd8cRENL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets use a specialized vison model\n",
        "\n",
        "visionmodel =  dspy.LM(\"gemini/gemini-2.5-flash\",api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "AM51eqsLCSaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_detector = dspy.Predict(NumberDetections)\n",
        "with dspy.context(lm = visionmodel):\n",
        "  detections = new_detector(image = numbers_image)\n",
        "print(detections)\n",
        "def draw_detectcions(image_url, detections):\n",
        "\n",
        "  # Read the image from the URL using the io module\n",
        "  with urllib.request.urlopen(image_url) as my_url_res:\n",
        "    my_img_data = my_url_res.read()\n",
        "\n",
        "  # Open the image in PIL\n",
        "  my_img = Image.open(BytesIO(my_img_data))\n",
        "\n",
        "  # Show the image\n",
        "  \"\"\"draw detections on image\"\"\"\n",
        "  from PIL import ImageDraw\n",
        "  image = my_img\n",
        "  draw = ImageDraw.Draw(image)\n",
        "  for detection in detections:\n",
        "    x_min, y_min, x_max, y_max = detection[\"x_min\"], detection[\"y_min\"], detection[\"x_max\"], detection[\"y_max\"]\n",
        "    scaled_x_min = int(x_min * image.width/1000)\n",
        "    scaled_y_min = int(y_min * image.height/1000)\n",
        "    scaled_x_max = int(x_max * image.width/1000)\n",
        "    scaled_y_max = int(y_max * image.height/1000)\n",
        "    draw.rectangle([(scaled_x_min, scaled_y_min), (scaled_x_max, scaled_y_max)], outline=\"red\", width=2)\n",
        "    draw.text((scaled_x_min, scaled_y_min), str(detection[\"number\"]), fill=\"red\")\n",
        "  return image\n",
        "draw_detectcions(image_url, detections.boxes)"
      ],
      "metadata": {
        "id": "_WzQtSDY_Zuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# changing models\n",
        "\n",
        "There are specialized or just more powerfull models that you can use for the task at hand"
      ],
      "metadata": {
        "id": "SgZ7nc4VE0EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum_of_numbers_haiku = dspy.ChainOfThought(NumberAdd) #models can be just not smart enough\n",
        "sum_of_numbers_haiku(numbers = \"dragon,siete, enterprise\") #frequentely answer either does not recognize that siete is a number or outputs both 7 and a haiku"
      ],
      "metadata": {
        "id": "IHvyt3RlmIcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "larger_lm = dspy.LM(\"gemini/gemini-2.5-flash\",api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "9yK5SkkvU_Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with dspy.context(lm = larger_lm): #so they can be replaced\n",
        "    sum_of_numbers_haiku = dspy.ChainOfThought(NumberAdd)\n",
        "    print(sum_of_numbers_haiku(numbers = \"dragon,siete, enterprise\"))"
      ],
      "metadata": {
        "id": "zVmlJLQ_nL5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try a specialized (and open) vision language model for image understanding\n",
        "# open router is a nice way to access them\n",
        "#visionmodel =  dspy.LM(model = \"openrouter/z-ai/glm-4.5v\",\n",
        "#                       api_key = OPENROUTER_API_KEY)\n"
      ],
      "metadata": {
        "id": "G2UeVN7jFMCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cost\n",
        "\n",
        "DSPy provides logs both on general, language model and module levels\n",
        "\n",
        "They are provided as history, where each call is explained"
      ],
      "metadata": {
        "id": "YfUeGrjUGMhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "big_cost = larger_lm.history[-1][\"cost\"]\n",
        "small_cost = small_model.history[-1][\"cost\"]\n",
        "\n",
        "print(f\"Big cost: {big_cost}\")\n",
        "print(f\"Small cost: {small_cost}\")\n",
        "print(f\"Smaller model is {big_cost/small_cost} times cheaper\")"
      ],
      "metadata": {
        "id": "iAQiPFi8VDHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying a chain of modules\n",
        "try_n = dspy.ChainOfThought(NumberAdd,n=5) # we ask the model 5 times\n",
        "best_of_n = dspy.MultiChainComparison(NumberAdd, M=5) # we compare the outputs and choose one\n",
        "tries = try_n(numbers = \"dragon,siete, enterprise\")\n",
        "tries.completions\n",
        "\n",
        "best_of_n(tries.completions)"
      ],
      "metadata": {
        "id": "mL3YjckMRhQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing own modules\n",
        "\n",
        "we can create our own modules, that allow us to combine strategies to fit our idea"
      ],
      "metadata": {
        "id": "7o6q3583GzD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "class BestNumber(dspy.Module):\n",
        "  \"\"\"module returns sum of numbers through generating multiple answers, analyzing them and\n",
        "  finally verifying the best answer\"\"\"\n",
        "  def __init__(self, n):\n",
        "    self.n = n\n",
        "    # will generate n answers\n",
        "    self.chain = dspy.ChainOfThought(NumberAdd, n=n)\n",
        "    signature_possible = NumberAdd.append(\"possible_answers\",\n",
        "                dspy.InputField(\n",
        "                    desc=\"choice of possible answers, with reasoning\",\n",
        "                ))\n",
        "    best_answer = dspy.ChainOfThought(signature_possible)\n",
        "\n",
        "    self.check_rule = dspy.Refine(best_answer, N=3, reward_fn=self.check_result, threshold=1.0)\n",
        "\n",
        "  def check_result(self, args, result):\n",
        "    \"\"\"when number is not zero, haiku should not be generated\"\"\"\n",
        "    rule_exclusive_or = (result.sum_of_numbers != 0) ^ (result.haiku is not None)\n",
        "    return rule_exclusive_or\n",
        "\n",
        "  def forward(self, numbers): #forward is the key to module behaviour, will be used during runtime, for logging and optimization\n",
        "    tries = self.chain(numbers=numbers)\n",
        "\n",
        "    final_answer = self.check_rule(possible_answers = tries.completions, numbers=numbers)\n",
        "\n",
        "    return final_answer"
      ],
      "metadata": {
        "id": "Su6ery_uewSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cYCvuPVQg1ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bestnumber = BestNumber(n=4)\n",
        "\n",
        "print(bestnumber(numbers = \"dragon,siete,enterprise\"))"
      ],
      "metadata": {
        "id": "w9zubdB5UeYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool use"
      ],
      "metadata": {
        "id": "tbXbuTOqHFZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy\n",
        "\n",
        "def symbolic_expression_sympy(expression: str, *Args) -> float:\n",
        "  \"\"\"\n",
        "  Takes a symbolic math expression (written as a string) and returns a result as a float, evaluated to 5 significant numbers, using sympy.\n",
        "  For example symbolic_expression_sympy(\"2*log(E)\") would result in 2.0000\n",
        "  \"\"\"\n",
        "  expr = sympy.sympify(expression)\n",
        "  return expr.evalf(5)\n"
      ],
      "metadata": {
        "id": "UE34kwv6uhZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_of_numbers_smarter = dspy.ReAct('numbers -> sum_of_numbers', tools=[symbolic_expression_sympy]) #re-act uses the tools provided and a chain of thought\n",
        "prediction = sum_of_numbers_smarter(numbers=[\"2*sin(10)\",\"pi\"])\n",
        "prediction\n"
      ],
      "metadata": {
        "id": "2R4YfpGUHC75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG\n",
        "Retreival-augmented generation is a common strategy to deliver context.\n",
        "\n",
        "Retretival can use tools such as reverse index search (akin to old school search engines with keywords) or embedding based search.\n",
        "\n",
        "DSPy can be easly connected to external vector databases (like chromadb),\n",
        "it plays nicely also with helper tools such as the ones in langchain (for reading standard fileformats, connecting to databases)\n",
        "\n",
        "The build in dspy.Embeddings tool uses FAISS internally"
      ],
      "metadata": {
        "id": "Kgo62yhJHS06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone http://github.com/python/peps.git #we will use all PEPs up to point as a knowledge base\n"
      ],
      "metadata": {
        "id": "ZKTR7Gv9HFDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "documents = []\n",
        "for filename in os.listdir('./peps/peps'):\n",
        "    if filename.endswith('.rst'):\n",
        "        filepath = os.path.join('./peps/peps', filename)\n",
        "        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            documents.append(f.read())\n",
        "\n",
        "print(f\"Loaded {len(documents)} documents.\")"
      ],
      "metadata": {
        "id": "Y4u17NLiHUqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install inverted-index #very simple inverted-index tool"
      ],
      "metadata": {
        "id": "zX1NEYywHT-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from inverted_index.inverted_index import InvertedIndex\n",
        "\n",
        "ii = InvertedIndex()\n",
        "\n",
        "ii.index(documents)"
      ],
      "metadata": {
        "id": "YfCprQzAHaZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ii.search(\"PEP 355\")"
      ],
      "metadata": {
        "id": "rcTjBty_HfUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using logging tools\n",
        "\n",
        "DSpy traces can be explored in MLOps tools such as Opik (Comet) or MLFlow. This allows to easly see how information flew or what were particular responses. Essential also for optimization. Personally I feel that MLFlow is now better integrated, try both"
      ],
      "metadata": {
        "id": "NmfsAgHpImLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opik\n",
        "from opik.integrations.dspy.callback import OpikCallback\n",
        "\n",
        "opik.configure(use_local=False)\n"
      ],
      "metadata": {
        "id": "EGziaG3vHoUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PEPSearch(dspy.Module):\n",
        "  def __init__(self):\n",
        "    self.respond = dspy.ChainOfThought('context_based_on_search, python_question -> easy_to_understand_response_based_on_PEP')\n",
        "    self.reverseindexquery = dspy.ChainOfThought('python_question -> query_to_reverse_index')\n",
        "  def forward(self, question):\n",
        "    query = self.reverseindexquery(python_question = question)\n",
        "    #print(query)\n",
        "    search_responses =\"\\n\\n\".join(ii.search(query.query_to_reverse_index)[0:10])\n",
        "    response = self.respond(context_based_on_search = search_responses, python_question = question)\n",
        "    return response.easy_to_understand_response_based_on_PEP"
      ],
      "metadata": {
        "id": "lugjDSsUHx0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pep_trivia = PEPSearch()\n",
        "\n",
        "pep_trivia(question = \"what is PEP 761 about?\")"
      ],
      "metadata": {
        "id": "zCGrt7RUIATR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = dspy.Embedder(\"gemini/embedding-001\", dimensions = 768,  api_key = GEMINI_API_KEY, batch_size = 20)\n",
        "embeddings_peps = dspy.Embeddings(embedder = embedder, corpus = documents, k = 5)\n",
        "class PEPEmbeddingRetreival(dspy.Module):\n",
        "  def __init__(self):\n",
        "    self.respond = dspy.ChainOfThought('context_based_on_search, python_question -> easy_to_understand_response_based_on_PEP')\n",
        "    self.reverseindexquery = dspy.ChainOfThought('python_question -> query_to_embbeding_based_search')\n",
        "  def forward(self, question):\n",
        "    query = self.reverseindexquery(python_question = question)\n",
        "    #print(query)\n",
        "    search_responses =embeddings_peps(query.query_to_embbeding_based_search)\n",
        "    response = self.respond(context_based_on_search = search_responses, python_question = question)\n",
        "    return response.easy_to_understand_response_based_on_PEP"
      ],
      "metadata": {
        "id": "Z20s4o76ID6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pep_trivia_embeddings = PEPEmbeddingRetreival()\n",
        "pep_trivia_embeddings(question = \"any news about python 3.14?\")"
      ],
      "metadata": {
        "id": "57s44YjbIQwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optimization\n",
        "\n",
        "DSPy key idea is that we first create the information flow system from components, focus on the context engineering while later align the models behaviours through compilation\n",
        "\n",
        "For that we need to have in place:\n",
        "\n",
        " - some datasets with expected outcomes\n",
        " - a metric (or metrics) that we will use to optimize. This metric can be a judge model with set of instructions (we can optimize even the judge)\n",
        " - choice of optimizers (teleprompters). Those vary on requirements (number of examples, type of metrics, helper functions) and scope of optimization: they can provide important examples (demos), optimize prompts or collaborate when finetuneing the model itself"
      ],
      "metadata": {
        "id": "dQcoQb7ZIZHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum_of_numbers_smarter = dspy.ReAct( #similar to previous ones but we ensure that output is float, very basic othervise.\n",
        "                                    #a one line instruction added based on what we need from the task\n",
        "    dspy.Signature('numbers -> sum_of_numbers:float',\"find all the numbers in any format and add them\"),\n",
        "                                    tools=[symbolic_expression_sympy])\n"
      ],
      "metadata": {
        "id": "DqbNoVJDJU_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets\n",
        "\n",
        "As with other machine-learning based systems it is important to have a datasets to verify againsts.\n",
        "\n",
        "In case of AI (LLM/VLM) based systems and the optimization strategies as those below these datasets:\n",
        "\n",
        " - Do not need to be very large. Tens to hundreds examples will do\n",
        " - Need to be very well checked as all the errors (outliers) will very probably end up as important examples or modify the prompt"
      ],
      "metadata": {
        "id": "oIzHL12TLotd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38ExhPrnLnxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing dataset\n",
        "examples_pairs = [\n",
        "    (\"siete banana dos\",9),\n",
        "     (\"one seven\",8),\n",
        "    (\"1,2,3\",6),\n",
        " (1,1),([\"exp(1)\",7],9.7183),(\"SIN(1) AND 1\",1.8415),\n",
        "                  (\"4,5,6\", 15),\n",
        " ([\"7\",\"8\",\"9\"], 24),\n",
        " (\"10 + 11\", 21),\n",
        " (\"3.1416 and 2.7183\", 5.8599),\n",
        " (\"-1, -2, 5\", 2),\n",
        " ([\"100\",\"200\",\"300\"], 600),\n",
        " (\"0.3333 + 0.6667\", 1.0),\n",
        " (\"SQRT(4) + 6\", 8.0),\n",
        " (\"2^3 and 1\", 9),\n",
        " ([\"12.5\",\"-2.5\"], 10.0),\n",
        " (\"0.1 + 0.2 + 0.3\", 0.6),\n",
        " (\"exp(1) + 3\", 5.7183),\n",
        " (\"cos(0)+1\", 2.0),\n",
        " (\"[‘foo’,42]\", 42),\n",
        " (\"99 bottles + 1\", 100),\n",
        " (\"1e3 + 2e3 + 3e3\", 6000),\n",
        " (\"π + 1\", 4.1416),\n",
        " (\"ln(10) + 2\", 4.3026),\n",
        " (\"tan(1) + 0\", 1.5574),\n",
        " (\"[‘3*3’, 4]\", 13),\n",
        "                  (\"2.5, 7.5\", 10.0),\n",
        " (\"sin(0.5) + cos(0.5)\", 1.3570),\n",
        " (\"log10(1000) + 4\", 7.0),\n",
        " (\"sqrt(2) + sqrt(3)\", 3.1463),\n",
        " (\"phi + 1\", 2.6180),              # golden ratio 1.6180 + 1\n",
        " (\"abs(-7) + 3\", 10.0),\n",
        " (\"round(2.718,2)+1\", 3.72),\n",
        " (\"sin(pi/2) + cos(0)\", 2.0),\n",
        " (\"arctan(1) + 1\", 1.7854),\n",
        " (\"sinh(1) + cosh(1)\", 2.7183),    # = e^1\n",
        " (\"exp(2) + 1\", 8.3891),\n",
        " (\"log(100) + 1\", 5.6052),         # natural log\n",
        " (\"7.77 + 8.88 + 9.99\", 26.64),\n",
        " (\"0.12345 + 0.54321\", 0.66666),\n",
        " (\"2π + e\", 9.0015),\n",
        " (\"gamma(5)\", 24.0),               # 4! = 24\n",
        " (\"erf(1) + 1\", 1.8427),\n",
        " (\"ceil(2.3)+floor(2.3)\", 5),\n",
        " (\"10^-2 + 10^-3\", 0.011),\n",
        " (\"sqrt(5) + sqrt(7)\", 4.8818),\n",
        " (\"sin(2) + cos(3)\", -0.0807),\n",
        " ([\"42\",\"banana\"], 42),              # keep numeric, ignore nonsense\n",
        " (\"pi^2 + e^2\", 17.2587),\n",
        " (\"'hello' + 'world'\", 0),           # no numeric\n",
        " (\"sqrt(11) + sqrt(13)\", 6.9222),\n",
        " (\"exp(0) + log(1)\", 1.0),\n",
        " (\"foo(99)\", 99),                    # keep numeric 99, ignore nonsense\n",
        " (\"tan(pi/4) + 10\", 11.0),\n",
        " (\"gamma(6)\", 120.0),\n",
        "    (\"raz dwa trzy\",6),\n",
        " ([\"dragon\",\"unicorn\"], 0),          # no numeric\n",
        " (\"1/3 + 2/3\", 1.0),\n",
        " (\"arcsin(1) + arccos(0)\", 3.1416),\n",
        " (\"NaN test\", 0),                    # no numeric\n",
        " (\"ln(50) + 0.5\", 4.4120),\n",
        " (\"e^3 + 2\", 22.085),\n",
        " (\"cosh(2) - sinh(2)\", 0.1353),         # = e^-2\n",
        " (\"weird#string\", 0),\n",
        " (\"10% of 200\", 20.0),\n",
        " (\"floor(7.9) + ceil(7.1)\", 15.0),\n",
        " ([\"None\",\"None\"], 0),               # no numeric\n",
        "                  ]\n",
        "examples = [] #converting to list of dspy.Examples\n",
        "for numbers,sum_of_numbers in examples_pairs:\n",
        "  examples.append(dspy.Example(numbers = numbers, sum_of_numbers = sum_of_numbers).with_inputs(\"numbers\"))"
      ],
      "metadata": {
        "id": "rX3LZCOdIbV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics\n",
        "\n",
        "Metrics ideally output a single value but for the tasks at hand it is important to understand what are the key properties of the answer\n",
        "\n",
        "Particuarly with approach such as GEPA, you can provide more feedback to the optimizer if for example the answer is too long, mathematically not correct or silly.\n",
        "\n",
        "Other language models can be judges quite effectively, particularly for typical language tasks (for vision in may be more tricky as there can be systematic errors in the way the image is encoded in both vlms that are used for inference and for judging)"
      ],
      "metadata": {
        "id": "mUCaZ0k2NJfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metric(example, pred, trace=None):\n",
        "    \"\"\"basic metric result should be aprox equal to gold\"\"\"\n",
        "    gold = example.sum_of_numbers\n",
        "    pred = pred.sum_of_numbers\n",
        "    return abs(gold - pred)<0.0001 #lets give some margin of error"
      ],
      "metadata": {
        "id": "ZYYMnMjyIXrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, devset, testset = examples[:40], examples[40:55], examples[55:]\n"
      ],
      "metadata": {
        "id": "0GjhpChiI7hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate = dspy.Evaluate(devset=devset, metric=metric, num_threads=4, display_progress=True,\n",
        "                         display_table=0, max_errors=999)"
      ],
      "metadata": {
        "id": "VJxmhDQ4I_9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resu = evaluate(sum_of_numbers_smarter)\n",
        "resu"
      ],
      "metadata": {
        "id": "phUyftd_JAYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeledfew = dspy.LabeledFewShot(k=3) #simples optimization will fill the demos part of model call\n",
        "\n",
        "optimizedlabelw = labeledfew.compile(sum_of_numbers_smarter, trainset=trainset)"
      ],
      "metadata": {
        "id": "TbZxuRGLJTyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizedlabelw(numbers = \"one, two\")"
      ],
      "metadata": {
        "id": "5wn4Y2GeJDUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizedlabelw.extract.predict.demos"
      ],
      "metadata": {
        "id": "mxle8xbwJnOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizedlabelw.save(\"few_shot.json\")"
      ],
      "metadata": {
        "id": "vEsErJZqKCK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simba = dspy.SIMBA(metric=metric, max_steps=3, max_demos=5)\n",
        "optimized_agent_simba = simba.compile(sum_of_numbers_smarter, trainset=trainset, seed=6793115)"
      ],
      "metadata": {
        "id": "uvm4E3JUKW3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simba = dspy.SIMBA(metric=metric, max_steps=3, max_demos=5)\n",
        "optimized_agent_simba = simba.compile(sum_of_numbers_smarter, trainset=trainset, seed=6793115)"
      ],
      "metadata": {
        "id": "vUk9UA_WKgdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(optimized_agent_simba)\n"
      ],
      "metadata": {
        "id": "i3DepUhGKxsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_agent_simba.extract.predict.demos"
      ],
      "metadata": {
        "id": "mhsGkqhIK5RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is opportunity to pass more knowledge about quality of the answer or some tips to the optimizer\n",
        "def metric_with_feedback(example,prediction,trace=None, pred_name=None, pred_trace = None):\n",
        "  correct_answer = float(example.sum_of_numbers)\n",
        "  try:\n",
        "    llm_answer = float(prediction.sum_of_numbers)\n",
        "  except:\n",
        "    llm_answer = \"it was not a number\"\n",
        "  score = float(metric(example,prediction))\n",
        "  feedback_text = \"\"\n",
        "  if score==1:\n",
        "    feedback_text = f\"Your answer is correct {correct_answer}\"\n",
        "  else:\n",
        "    print(example)\n",
        "    feedback_text = f\"Your answer: {llm_answer} is not correct, it should be {correct_answer}\"\n",
        "    print(feedback_text)\n",
        "  return dspy.Prediction(score = score, feedback = feedback_text)"
      ],
      "metadata": {
        "id": "TnTYgQ4xK5--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gepa_optimizer = optimizer = dspy.GEPA(\n",
        "    metric=metric_with_feedback,\n",
        "    #auto=\"light\",\n",
        "    max_metric_calls=200,\n",
        "    num_threads=32,\n",
        "    track_stats=True,\n",
        "    reflection_minibatch_size=3,\n",
        "    reflection_lm=dspy.LM(model=\"gemini/gemini-2.5-flash\", temperature=1.0, max_tokens=32000,  api_key=GEMINI_API_KEY) #note that these models receive a large part of history, houndreds of thousands of tokens\n",
        ")\n",
        "gepa_optimized_program = optimizer.compile(\n",
        "    sum_of_numbers_smarter,\n",
        "    trainset=trainset,\n",
        "    valset=devset,\n",
        ")"
      ],
      "metadata": {
        "id": "Ousd9TByK-uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gepa_optimized_program.save(\"gepa.json\")"
      ],
      "metadata": {
        "id": "vtiADDVZLCJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(gepa_optimized_program)"
      ],
      "metadata": {
        "id": "WYhbQCElLBhJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}